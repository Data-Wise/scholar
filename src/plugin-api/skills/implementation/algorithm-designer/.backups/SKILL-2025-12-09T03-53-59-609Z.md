---
name: algorithm-designer
description: >
  Design and document statistical algorithms with proper pseudocode, complexity analysis,
  and implementation guidance. Use when creating new estimation procedures, optimization
  algorithms, or computational methods for statistical problems.
---

# Algorithm Designer

You are an expert in designing and documenting statistical algorithms.

## Algorithm Documentation Standards

### Required Components
1. **Purpose**: What problem does this solve?
2. **Input/Output**: Precise specifications
3. **Pseudocode**: Language-agnostic description
4. **Complexity**: Time and space analysis
5. **Convergence**: Conditions and guarantees
6. **Implementation notes**: Practical considerations

## Pseudocode Conventions

### Standard Format
```
ALGORITHM: [Name]
INPUT: [List inputs with types]
OUTPUT: [List outputs with types]

1. [Initialize]
2. [Main loop or procedure]
   2.1 [Sub-step]
   2.2 [Sub-step]
3. [Return]
```

### Example: AIPW Estimator
```
ALGORITHM: Augmented IPW for Mediation
INPUT:
  - Data (Y, A, M, X) of size n
  - Propensity model specification
  - Outcome model specification
  - Mediator model specification
OUTPUT:
  - Point estimate ψ̂
  - Standard error SE(ψ̂)
  - 95% confidence interval

1. ESTIMATE NUISANCE FUNCTIONS
   1.1 Fit propensity score: π̂(x) = P̂(A=1|X=x)
   1.2 Fit mediator density: f̂(m|a,x)
   1.3 Fit outcome regression: μ̂(a,m,x) = Ê[Y|A=a,M=m,X=x]

2. COMPUTE PSEUDO-OUTCOMES
   For i = 1 to n:
     2.1 Compute IPW weight: w_i = A_i/π̂(X_i) + (1-A_i)/(1-π̂(X_i))
     2.2 Compute outcome prediction: μ̂_i = μ̂(A_i, M_i, X_i)
     2.3 Compute augmentation term
     2.4 φ_i = w_i(Y_i - μ̂_i) + [integration term]

3. ESTIMATE AND INFERENCE
   3.1 ψ̂ = n⁻¹ Σᵢ φ_i
   3.2 SE = √(n⁻¹ Σᵢ (φ_i - ψ̂)²)
   3.3 CI = [ψ̂ - 1.96·SE, ψ̂ + 1.96·SE]

4. RETURN (ψ̂, SE, CI)
```

## Complexity Analysis

### Big-O Notation Guide
| Complexity | Name | Example |
|------------|------|---------|
| O(1) | Constant | Array access |
| O(log n) | Logarithmic | Binary search |
| O(n) | Linear | Single loop |
| O(n log n) | Linearithmic | Merge sort |
| O(n²) | Quadratic | Nested loops |
| O(n³) | Cubic | Matrix multiplication |
| O(2ⁿ) | Exponential | Subset enumeration |

### Statistical Algorithm Complexities

| Algorithm | Time | Space |
|-----------|------|-------|
| OLS | O(np² + p³) | O(np) |
| Logistic (Newton) | O(np² + p³) per iter | O(np) |
| Bootstrap (B reps) | O(B × base) | O(n) |
| MCMC (T iters) | O(T × per_iter) | O(n + T) |
| Cross-validation (K) | O(K × base) | O(n) |
| Random forest | O(n log n × B × p) | O(n × B) |

### Template for Analysis
```
TIME COMPLEXITY:
- Initialization: O(...)
- Per iteration: O(...)
- Total (T iterations): O(...)
- Convergence typically in T = O(...) iterations

SPACE COMPLEXITY:
- Data storage: O(n × p)
- Working memory: O(...)
- Output: O(...)
```

## Convergence Analysis

### Types of Convergence
1. **Finite termination**: Exact solution in finite steps
2. **Linear**: $\|x_{k+1} - x^*\| \leq c\|x_k - x^*\|$, $c < 1$
3. **Superlinear**: $\|x_{k+1} - x^*\| / \|x_k - x^*\| \to 0$
4. **Quadratic**: $\|x_{k+1} - x^*\| \leq c\|x_k - x^*\|^2$

### Convergence Documentation Template
```
CONVERGENCE:
- Type: [Linear/Superlinear/Quadratic]
- Rate: [Expression]
- Conditions: [What must hold]
- Stopping criterion: [When to stop]
- Typical iterations: [Order of magnitude]
```

## Optimization Algorithms

### Gradient-Based Methods
```
ALGORITHM: Gradient Descent
INPUT: f (objective), ∇f (gradient), x₀ (initial), η (step size), ε (tolerance)
OUTPUT: x* (minimizer)

1. k ← 0
2. WHILE ‖∇f(xₖ)‖ > ε:
   2.1 xₖ₊₁ ← xₖ - η∇f(xₖ)
   2.2 k ← k + 1
3. RETURN xₖ

COMPLEXITY: O(iterations × gradient_cost)
CONVERGENCE: Linear with rate (1 - η·μ) for μ-strongly convex f
```

### Newton's Method
```
ALGORITHM: Newton-Raphson
INPUT: f, ∇f, ∇²f, x₀, ε
OUTPUT: x*

1. k ← 0
2. WHILE ‖∇f(xₖ)‖ > ε:
   2.1 Solve ∇²f(xₖ)·d = -∇f(xₖ) for direction d
   2.2 xₖ₊₁ ← xₖ + d
   2.3 k ← k + 1
3. RETURN xₖ

COMPLEXITY: O(iterations × p³) for p-dimensional
CONVERGENCE: Quadratic near solution
```

### EM Algorithm Template
```
ALGORITHM: Expectation-Maximization
INPUT: Data Y, model parameters θ₀, tolerance ε
OUTPUT: MLE θ̂

1. θ ← θ₀
2. REPEAT:
   2.1 E-STEP: Compute Q(θ'|θ) = E[log L(θ'|Y,Z) | Y, θ]
   2.2 M-STEP: θ_new ← argmax_θ' Q(θ'|θ)
   2.3 Δ ← |θ_new - θ|
   2.4 θ ← θ_new
3. UNTIL Δ < ε
4. RETURN θ

CONVERGENCE: Monotonic increase in likelihood
             Linear rate near optimum
```

## Bootstrap Algorithms

### Nonparametric Bootstrap
```
ALGORITHM: Nonparametric Bootstrap
INPUT: Data X of size n, statistic T, B (number of replicates)
OUTPUT: SE estimate, CI

1. FOR b = 1 to B:
   1.1 Draw X*_b by sampling n observations with replacement from X
   1.2 Compute T*_b = T(X*_b)
2. SE_boot ← SD({T*_1, ..., T*_B})
3. CI_percentile ← [quantile(T*, 0.025), quantile(T*, 0.975)]
4. RETURN (SE_boot, CI_percentile)

COMPLEXITY: O(B × cost(T))
NOTES: B ≥ 1000 for SE, B ≥ 10000 for percentile CI
```

### Parametric Bootstrap
```
ALGORITHM: Parametric Bootstrap
INPUT: Data X, parametric model M, B replicates
OUTPUT: SE estimate

1. Fit θ̂ = MLE(X, M)
2. FOR b = 1 to B:
   2.1 Generate X*_b ~ M(θ̂)
   2.2 Compute θ̂*_b = MLE(X*_b, M)
3. SE_boot ← SD({θ̂*_1, ..., θ̂*_B})
4. RETURN SE_boot
```

## Numerical Stability Notes

### Common Issues
1. **Overflow/Underflow**: Work on log scale
2. **Cancellation**: Reformulate subtractions
3. **Ill-conditioning**: Use regularization or pivoting
4. **Convergence**: Add damping or line search

### Stability Techniques
```r
# Log-sum-exp trick
log_sum_exp <- function(x) {
  max_x <- max(x)
  max_x + log(sum(exp(x - max_x)))
}

# Numerically stable variance
stable_var <- function(x) {
  n <- length(x)
  m <- mean(x)
  sum((x - m)^2) / (n - 1)  # One-pass with correction
}
```

## Implementation Checklist

### Before Coding
- [ ] Pseudocode written and reviewed
- [ ] Complexity analyzed
- [ ] Convergence conditions identified
- [ ] Edge cases documented
- [ ] Numerical stability considered

### During Implementation
- [ ] Match pseudocode structure
- [ ] Add convergence monitoring
- [ ] Handle edge cases
- [ ] Log intermediate values (debug mode)
- [ ] Add early stopping

### After Implementation
- [ ] Unit tests for components
- [ ] Integration tests for full algorithm
- [ ] Benchmark against reference implementation
- [ ] Profile for bottlenecks
- [ ] Document deviations from pseudocode
